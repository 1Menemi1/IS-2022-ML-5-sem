{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGClrhQA9SAk"
      },
      "source": [
        "# Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veekMy8WRjBi"
      },
      "source": [
        "## Построение дерева"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkVwAFiUHXj"
      },
      "source": [
        "Опишем жадный алгоритм построения бинарного дерева решений:\n",
        "1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$. \n",
        "2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки. \n",
        "3. Запускаем построение из корня: $SplitNode(1, R_1)$\n",
        "\n",
        "Функция $SplitNode(m, R_m)$\n",
        "1. Если выполнен критерий остановки, то выход.\n",
        "2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n",
        "3. Помещаем предикат в вкршину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n",
        "4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n",
        "5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n",
        "\n",
        "В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n",
        "$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P6FsdBog4Ai"
      },
      "source": [
        "## Функционал качества для деревьев решений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAKO0aykGBD"
      },
      "source": [
        "Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n",
        "$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5582B-1Fn2bw"
      },
      "source": [
        "где $p_i$ – вероятности нахождения системы в $i$-ом состоянии. \n",
        "\n",
        "Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbcMUd7bvk05"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "from pprint import pprint\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AdLxP9CowTm"
      },
      "source": [
        "Код для расчёта энтропии:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mT8Jq8Av2sM"
      },
      "source": [
        "def entropy(y):\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "    return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9etb2vo7fK"
      },
      "source": [
        "Здесь $y$ - это массив значений целевой переменной"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07TCw0USzLus"
      },
      "source": [
        "Энтропия – по сути степень хаоса (или неопределенности) в системе. Уменьшение энтропии называют приростом информации (information gain, IG).\n",
        "\n",
        "Обочначим $R_v$ - объекты, которые нужно разделить в помощью предиката в вершине $v$. Запишем формулу для расчёта информационного прироста:\n",
        "$$ Q = IG = H(R_v) - (H(R_{left})+H(R_{right}))$$\n",
        "\n",
        "На каждом шаге нам нужно максимизировать этот функционал качества. Как это делать? Например, так можно перебрать $t$ для выбранного $j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trEWHDoXg_p9"
      },
      "source": [
        "Предыдущая версия формулы прироста информации слишком упрощена. В работе необходимо использовать более устойчивую формулу, которая учитывает не только энтропию подмножеств, но и их размер. \n",
        "\n",
        "$$ Q = IG = H(R_v) - \\Big (\\frac{|R_{left}|} {|R_{v}|} H(R_{left})+ \\frac{|R_{right}|} {|R_{v}|} H(R_{right})\\Big)$$\n",
        "\n",
        "где, $|R_{v}|$, $|R_{left}|$ и $|R_{right}|$ - количество элементов в соответствующих множествах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmN6V_N1xBr"
      },
      "source": [
        "\n",
        "### Задание 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFHZScF2CBF"
      },
      "source": [
        "Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения узлов дерева (используйте, например, `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признаков и порогов), для проверки критерия остановки.\n",
        "\n",
        "Для набора данных `iris` реализуйте алгоритм и минимум три из разными критерия остановки из перечисленных ниже:\n",
        "* максимальной глубины дерева = 5\n",
        "* минимального числа объектов в листе = 5\n",
        "* максимальное количество листьев в дереве = 5\n",
        "* purity (остановка, если все объекты в листе относятся к одному классу)\n",
        "\n",
        "Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n",
        "\n",
        "Оцените точность каждой модели с помощью метрики доля правильных ответов (`from sklearn.metrics import accuracy_score` или реализовать свою)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Реализация"
      ],
      "metadata": {
        "id": "E-RyguSy1RWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "\n",
        "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tWd6DzN4u0mR",
        "outputId": "ca51c313-e512-425c-9e05-f64fd295d488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                  5.1               3.5                1.4               0.2   \n",
              "1                  4.9               3.0                1.4               0.2   \n",
              "2                  4.7               3.2                1.3               0.2   \n",
              "3                  4.6               3.1                1.5               0.2   \n",
              "4                  5.0               3.6                1.4               0.2   \n",
              "..                 ...               ...                ...               ...   \n",
              "145                6.7               3.0                5.2               2.3   \n",
              "146                6.3               2.5                5.0               1.9   \n",
              "147                6.5               3.0                5.2               2.0   \n",
              "148                6.2               3.4                5.4               2.3   \n",
              "149                5.9               3.0                5.1               1.8   \n",
              "\n",
              "     target  \n",
              "0       0.0  \n",
              "1       0.0  \n",
              "2       0.0  \n",
              "3       0.0  \n",
              "4       0.0  \n",
              "..      ...  \n",
              "145     2.0  \n",
              "146     2.0  \n",
              "147     2.0  \n",
              "148     2.0  \n",
              "149     2.0  \n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61b5dc8c-ed0a-4f3f-96f6-526e7c9d4774\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61b5dc8c-ed0a-4f3f-96f6-526e7c9d4774')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61b5dc8c-ed0a-4f3f-96f6-526e7c9d4774 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61b5dc8c-ed0a-4f3f-96f6-526e7c9d4774');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_func(j, t, df):\n",
        "    left = df[df[df.columns[j]] < t]\n",
        "    right = df[df[df.columns[j]] >= t]\n",
        "\n",
        "    return left, right\n",
        "\n",
        "\n",
        "def IG_calc(df, sample1, sample2):\n",
        "    size_R_v = len(df[df.columns[-1]])\n",
        "    size_R_left = len(sample1[sample1.columns[-1]])\n",
        "    size_R_right = len(sample2[sample2.columns[-1]])\n",
        "\n",
        "    IG = entropy(df[df.columns[-1]]) - (\n",
        "            size_R_left / size_R_v * entropy(sample1[sample1.columns[-1]]) +\n",
        "            size_R_right / size_R_v * entropy(sample2[sample2.columns[-1]])\n",
        "    )\n",
        "\n",
        "    return IG\n",
        "\n",
        "\n",
        "def get_best_split(df):\n",
        "    best_j, best_t, best_IG = 0, 0.0, 0.0\n",
        "\n",
        "    for j in range(len(df.columns) - 1):\n",
        "        for t in df[df.columns[j]]:\n",
        "            left, right = split_func(j, t, df)\n",
        "            cur_IG = IG_calc(df, left, right)\n",
        "\n",
        "            if cur_IG > best_IG:\n",
        "                best_j, best_t, best_IG = j, t, cur_IG\n",
        "\n",
        "    return {'index': best_j, 'value': best_t, 'children': split_func(best_j, best_t, df)}\n",
        "\n",
        "\n",
        "def to_terminal(sample):\n",
        "    return sample[sample.columns[-1]].value_counts().index[0]\n",
        "\n",
        "\n",
        "def split_node(node, max_depth, min_size, purity, depth):\n",
        "    left, right = node['children']\n",
        "    del (node['children'])\n",
        "\n",
        "    if purity:\n",
        "        if left.value_counts().size == 1:\n",
        "            to_terminal(left)\n",
        "            return\n",
        "        if right.value_counts().size == 1:\n",
        "            to_terminal(right)\n",
        "            return\n",
        "\n",
        "    if left.empty or right.empty:\n",
        "        node['left'] = node['right'] = to_terminal(pd.concat([left, right]))\n",
        "        return\n",
        "\n",
        "    if depth >= max_depth:\n",
        "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
        "        return\n",
        "\n",
        "    if len(left) <= min_size:\n",
        "        node['left'] = to_terminal(left)\n",
        "    else:\n",
        "        node['left'] = get_best_split(left)\n",
        "        split_node(node['left'], max_depth, min_size, purity, depth + 1)\n",
        "\n",
        "    if len(right) <= min_size:\n",
        "        node['right'] = to_terminal(right)\n",
        "    else:\n",
        "        node['right'] = get_best_split(right)\n",
        "        split_node(node['right'], max_depth, min_size, purity, depth + 1)\n",
        "\n",
        "\n",
        "def build_tree(train, max_depth, min_size, purity):\n",
        "    root = get_best_split(train)\n",
        "    split_node(root, max_depth, min_size, purity, 1)\n",
        "    return root\n",
        "\n",
        "\n",
        "def predict_row(node, df_row):\n",
        "    if df_row[df_row.columns[node['index']]].iloc[0] < node['value']:\n",
        "        if isinstance(node['left'], dict):\n",
        "            return predict_row(node['left'], df_row)\n",
        "        else:\n",
        "            return node['left']\n",
        "    else:\n",
        "        if isinstance(node['right'], dict):\n",
        "            return predict_row(node['right'], df_row)\n",
        "        else:\n",
        "            return node['right']\n",
        "\n",
        "\n",
        "def predict_df(node, df_test):\n",
        "    y_pred = []\n",
        "    for i in range(df_test.shape[0]):\n",
        "        df_row = df_test.iloc[[i]]\n",
        "        pred_class = predict_row(node, df_row)\n",
        "\n",
        "        y_pred.append(pred_class)\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "yIWGQTbKvNEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Тестирование программы"
      ],
      "metadata": {
        "id": "E7Xkyzx5zVG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 120\n",
        "df_train = df.sample(train_size, random_state=42)\n",
        "df_test = df.drop(df_train.index)\n",
        "\n",
        "max_depth = 3\n",
        "min_size = 1\n",
        "tree = build_tree(df_train, max_depth, min_size, False)"
      ],
      "metadata": {
        "id": "t7ClsHiTzUir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "for depth in range(1, 10):\n",
        "    tree = build_tree(df_train, depth, 1, False)\n",
        "\n",
        "    accuracies.append(accuracy_score(df_test[df_test.columns[-1]], predict_df(tree, df_test)))\n",
        "\n",
        "plt.plot(range(1, 10), accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ub0K4ImvzsEj",
        "outputId": "c7c02f47-c910-4cd3-a804-03dfbe480895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5a19899d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По графику наглядно видно, что наилучшая глубина - 3, где `accuracy` достигает максимального значения из всех, что у нас есть. Дальнейшее же усложнение дерева приведёт к переобучению."
      ],
      "metadata": {
        "id": "5-oo5Y3S01YZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyCjLcy_CTM"
      },
      "source": [
        "##  Случайный лес"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKZe1FyRgCa"
      },
      "source": [
        "Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n",
        "\n",
        "1. Зададим $N$ - число деревьев в лесу.\n",
        "2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n",
        "3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n",
        "4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBQ8lc0WyrN"
      },
      "source": [
        "### Задание 4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y594Jn04ZTCm"
      },
      "source": [
        "В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n",
        "\n",
        "Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be_mLbdVW2oG"
      },
      "source": [
        "Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\". \n",
        "\n",
        "Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n",
        "\n",
        "Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n",
        "\n",
        "В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."
      ]
    }
  ]
}